{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuqRY6bJSe21",
        "outputId": "517ce477-09bd-490d-8a4b-c5f4a340f2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-sx8u72ts\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-sx8u72ts\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802825 sha256=00791126cc76ce18f52d701319eac7b1d76d0584858ab1171d301ee9ce601405\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4xxyo2po/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.2\n"
          ]
        }
      ],
      "source": [
        "# %pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj1mkehcNIBy",
        "outputId": "02ceb475-56d4-4f65-ef3c-9ffb750fb63e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting yt-dlp\n",
            "  Downloading yt_dlp-2023.12.30-py2.py3-none-any.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mutagen (from yt-dlp)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt-dlp)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2023.11.17)\n",
            "Requirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt-dlp) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt-dlp)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt-dlp)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt-dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 websockets-12.0 yt-dlp-2023.12.30\n"
          ]
        }
      ],
      "source": [
        "# %pip install yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bJVhmiOsTdfB"
      },
      "outputs": [],
      "source": [
        "YDL_OPTS = {\n",
        "    \"extract-audio\": True,\n",
        "    \"audio-format\": \"opus\",\n",
        "    \"noplaylist\": True,\n",
        "    \"youtube_include_dash_manifest\": False,\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'mp3',\n",
        "    }]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DzR8WH1STfFK"
      },
      "outputs": [],
      "source": [
        "from yt_dlp import YoutubeDL\n",
        "\n",
        "def extract_audio(filename: str, file_ext: str, url: str):\n",
        "    YDL_OPTS[\"postprocessors\"][0][\"preferredcodec\"] = file_ext\n",
        "    YDL_OPTS[\"outtmpl\"] = filename\n",
        "\n",
        "    with YoutubeDL(YDL_OPTS) as ydl:\n",
        "        ydl.download(url_list=[url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N76JWYgThIE",
        "outputId": "f8d6c4c0-6f48-4158-c326-64630932acea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=7h732qLxtAk\n",
            "[youtube] 7h732qLxtAk: Downloading webpage\n",
            "[youtube] 7h732qLxtAk: Downloading ios player API JSON\n",
            "[youtube] 7h732qLxtAk: Downloading android player API JSON\n",
            "[youtube] 7h732qLxtAk: Downloading m3u8 information\n",
            "[info] 7h732qLxtAk: Downloading 1 format(s): 313+251\n",
            "[download] Destination: test_audio.f313.webm\n",
            "[download] 100% of  153.51MiB in 00:00:02 at 52.35MiB/s  \n",
            "[download] Destination: test_audio.f251.webm\n",
            "[download] 100% of    4.25MiB in 00:00:00 at 34.59MiB/s  \n",
            "[Merger] Merging formats into \"test_audio.webm\"\n",
            "Deleting original file test_audio.f251.webm (pass -k to keep)\n",
            "Deleting original file test_audio.f313.webm (pass -k to keep)\n",
            "[ExtractAudio] Destination: test_audio.mp3\n",
            "Deleting original file test_audio.webm (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "extract_audio(filename=\"test_audio\", file_ext=\"mp3\", url=\"https://www.youtube.com/watch?v=7h732qLxtAk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCbLAp1ATqRy",
        "outputId": "c464e9c3-c29b-40d4-b149-c3972b68c6dc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"test_audio.mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YpCJ-W65V7BE"
      },
      "outputs": [],
      "source": [
        "from datetime import timedelta\n",
        "import csv\n",
        "\n",
        "with open(\"output.csv\", \"w\") as file:\n",
        "    w = csv.writer(file)\n",
        "    for seg in result.get(\"segments\", []):\n",
        "        start = timedelta(seconds=seg[\"start\"])\n",
        "        end = timedelta(seconds=seg[\"end\"])\n",
        "        text = seg[\"text\"]\n",
        "        text = text.lstrip()\n",
        "        row = [start, end, text]\n",
        "        w.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vE1LPHz-V_3-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = []\n",
        "for seg in result.get(\"segments\", []):\n",
        "    start = timedelta(seconds=seg[\"start\"])\n",
        "    end = timedelta(seconds=seg[\"end\"])\n",
        "    text = seg[\"text\"]\n",
        "    text = text.lstrip()\n",
        "    data.append([start, end, text])\n",
        "\n",
        "columns = [\"start_time\", \"end_time\", \"text\"]\n",
        "df = pd.DataFrame(data, columns=columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "4QZh-e4uU03Y",
        "outputId": "b27853a6-d224-4dec-84bd-e296e8382395"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-20124c04-b414-41b8-838d-fa1e94f34e00\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0 days 00:00:00</td>\n",
              "      <td>0 days 00:00:03.600000</td>\n",
              "      <td>Recently, the founder of Stability AI made an ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0 days 00:00:03.600000</td>\n",
              "      <td>0 days 00:00:05</td>\n",
              "      <td>There are no programmers in 5 years.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0 days 00:00:05</td>\n",
              "      <td>0 days 00:00:07</td>\n",
              "      <td>There are no programmers in 5 years.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0 days 00:00:07</td>\n",
              "      <td>0 days 00:00:10</td>\n",
              "      <td>Just two years ago, nobody was using AI code a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0 days 00:00:10</td>\n",
              "      <td>0 days 00:00:13.200000</td>\n",
              "      <td>but two years after GitHub Copilot Beta was la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0 days 00:04:41.500000</td>\n",
              "      <td>0 days 00:04:44.500000</td>\n",
              "      <td>And it's going to take some good old-fashioned...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>0 days 00:04:44.500000</td>\n",
              "      <td>0 days 00:04:46.100000</td>\n",
              "      <td>to do that. So stay optimistic.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>0 days 00:04:46.100000</td>\n",
              "      <td>0 days 00:04:47.200000</td>\n",
              "      <td>This has been the Code Report.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>0 days 00:04:47.200000</td>\n",
              "      <td>0 days 00:04:48.200000</td>\n",
              "      <td>Thanks for watching,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0 days 00:04:48.200000</td>\n",
              "      <td>0 days 00:04:49.700000</td>\n",
              "      <td>and I will see you in the next one.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>108 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-20124c04-b414-41b8-838d-fa1e94f34e00')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-20124c04-b414-41b8-838d-fa1e94f34e00 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-20124c04-b414-41b8-838d-fa1e94f34e00');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-edcea77c-f240-4424-85d5-c93cf74f078a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-edcea77c-f240-4424-85d5-c93cf74f078a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-edcea77c-f240-4424-85d5-c93cf74f078a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                start_time               end_time  \\\n",
              "0          0 days 00:00:00 0 days 00:00:03.600000   \n",
              "1   0 days 00:00:03.600000        0 days 00:00:05   \n",
              "2          0 days 00:00:05        0 days 00:00:07   \n",
              "3          0 days 00:00:07        0 days 00:00:10   \n",
              "4          0 days 00:00:10 0 days 00:00:13.200000   \n",
              "..                     ...                    ...   \n",
              "103 0 days 00:04:41.500000 0 days 00:04:44.500000   \n",
              "104 0 days 00:04:44.500000 0 days 00:04:46.100000   \n",
              "105 0 days 00:04:46.100000 0 days 00:04:47.200000   \n",
              "106 0 days 00:04:47.200000 0 days 00:04:48.200000   \n",
              "107 0 days 00:04:48.200000 0 days 00:04:49.700000   \n",
              "\n",
              "                                                  text  \n",
              "0    Recently, the founder of Stability AI made an ...  \n",
              "1                 There are no programmers in 5 years.  \n",
              "2                 There are no programmers in 5 years.  \n",
              "3    Just two years ago, nobody was using AI code a...  \n",
              "4    but two years after GitHub Copilot Beta was la...  \n",
              "..                                                 ...  \n",
              "103  And it's going to take some good old-fashioned...  \n",
              "104                    to do that. So stay optimistic.  \n",
              "105                     This has been the Code Report.  \n",
              "106                               Thanks for watching,  \n",
              "107                and I will see you in the next one.  \n",
              "\n",
              "[108 rows x 3 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czBHXELISwwU",
        "outputId": "9ddf8cc2-6369-4613-f38c-43e5a3d45e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'id': 0, 'seek': 0, 'start': 0.0, 'end': 3.6, 'text': ' Recently, the founder of Stability AI made an ominous prediction.', 'tokens': [50364, 20072, 11, 264, 14917, 295, 745, 2310, 7318, 1027, 364, 46812, 563, 17630, 13, 50544], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 1, 'seek': 0, 'start': 3.6, 'end': 5.0, 'text': ' There are no programmers in 5 years.', 'tokens': [50544, 821, 366, 572, 41504, 294, 1025, 924, 13, 50614], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 2, 'seek': 0, 'start': 5.0, 'end': 7.0, 'text': ' There are no programmers in 5 years.', 'tokens': [50614, 821, 366, 572, 41504, 294, 1025, 924, 13, 50714], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 3, 'seek': 0, 'start': 7.0, 'end': 10.0, 'text': ' Just two years ago, nobody was using AI code assistance,', 'tokens': [50714, 1449, 732, 924, 2057, 11, 5079, 390, 1228, 7318, 3089, 9683, 11, 50864], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 4, 'seek': 0, 'start': 10.0, 'end': 13.200000000000001, 'text': \" but two years after GitHub Copilot Beta was launched, we're now here.\", 'tokens': [50864, 457, 732, 924, 934, 23331, 11579, 31516, 33286, 390, 8730, 11, 321, 434, 586, 510, 13, 51024], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 5, 'seek': 0, 'start': 13.200000000000001, 'end': 16.4, 'text': ' 41% of all code on GitHub right now is AI generated.', 'tokens': [51024, 18173, 4, 295, 439, 3089, 322, 23331, 558, 586, 307, 7318, 10833, 13, 51184], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 6, 'seek': 0, 'start': 16.4, 'end': 18.8, 'text': \" That's a crazy claim, and I'd be highly skeptical of it,\", 'tokens': [51184, 663, 311, 257, 3219, 3932, 11, 293, 286, 1116, 312, 5405, 28601, 295, 309, 11, 51304], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 7, 'seek': 0, 'start': 18.8, 'end': 21.6, 'text': \" but I'd believe it next year after looking at these crazy new updates\", 'tokens': [51304, 457, 286, 1116, 1697, 309, 958, 1064, 934, 1237, 412, 613, 3219, 777, 9205, 51444], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 8, 'seek': 0, 'start': 21.6, 'end': 24.400000000000002, 'text': \" in GitHub Copilot, the launch of Google's duet AI,\", 'tokens': [51444, 294, 23331, 11579, 31516, 11, 264, 4025, 295, 3329, 311, 1581, 302, 7318, 11, 51584], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 9, 'seek': 0, 'start': 24.400000000000002, 'end': 27.900000000000002, 'text': ' and the launch of JetBrains AI, all of which just happened in the last few days.', 'tokens': [51584, 293, 264, 4025, 295, 28730, 45606, 1292, 7318, 11, 439, 295, 597, 445, 2011, 294, 264, 1036, 1326, 1708, 13, 51759], 'temperature': 0.0, 'avg_logprob': -0.134002624413906, 'compression_ratio': 1.7839506172839505, 'no_speech_prob': 0.02731705643236637}, {'id': 10, 'seek': 2790, 'start': 27.9, 'end': 31.599999999999998, 'text': \" It is December 14th, 2023, and you're watching the code report.\", 'tokens': [50364, 467, 307, 7687, 3499, 392, 11, 44377, 11, 293, 291, 434, 1976, 264, 3089, 2275, 13, 50549], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 11, 'seek': 2790, 'start': 31.599999999999998, 'end': 33.9, 'text': ' Before we get into this video, first a disclaimer.', 'tokens': [50549, 4546, 321, 483, 666, 341, 960, 11, 700, 257, 40896, 13, 50664], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 12, 'seek': 2790, 'start': 33.9, 'end': 37.5, 'text': \" The tools we're about to look at may make you want to drop out of your computer science degree\", 'tokens': [50664, 440, 3873, 321, 434, 466, 281, 574, 412, 815, 652, 291, 528, 281, 3270, 484, 295, 428, 3820, 3497, 4314, 50844], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 13, 'seek': 2790, 'start': 37.5, 'end': 38.9, 'text': ' and switch your major to plumbing.', 'tokens': [50844, 293, 3679, 428, 2563, 281, 39993, 13, 50914], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 14, 'seek': 2790, 'start': 38.9, 'end': 42.5, 'text': \" But that would be dumb, because they're also coming out with AI-powered smart toilets.\", 'tokens': [50914, 583, 300, 576, 312, 10316, 11, 570, 436, 434, 611, 1348, 484, 365, 7318, 12, 27178, 4069, 37691, 13, 51094], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 15, 'seek': 2790, 'start': 42.5, 'end': 46.2, 'text': ' But more importantly, pessimism leads to weakness, optimism leads to power.', 'tokens': [51094, 583, 544, 8906, 11, 37399, 1434, 6689, 281, 12772, 11, 31074, 6689, 281, 1347, 13, 51279], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 16, 'seek': 2790, 'start': 46.2, 'end': 48.5, 'text': \" It's possible programmers won't exist in 5 years,\", 'tokens': [51279, 467, 311, 1944, 41504, 1582, 380, 2514, 294, 1025, 924, 11, 51394], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 17, 'seek': 2790, 'start': 48.5, 'end': 52.4, 'text': \" but it's also possible that programmers will get paid 5 times as much in 5 years\", 'tokens': [51394, 457, 309, 311, 611, 1944, 300, 41504, 486, 483, 4835, 1025, 1413, 382, 709, 294, 1025, 924, 51589], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 18, 'seek': 2790, 'start': 52.4, 'end': 55.4, 'text': ' because everyone got discouraged and quit computer science in 2023.', 'tokens': [51589, 570, 1518, 658, 35010, 293, 10366, 3820, 3497, 294, 44377, 13, 51739], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 19, 'seek': 2790, 'start': 55.4, 'end': 57.7, 'text': ' Okay, so now that we have that optimism out of the way,', 'tokens': [51739, 1033, 11, 370, 586, 300, 321, 362, 300, 31074, 484, 295, 264, 636, 11, 51854], 'temperature': 0.0, 'avg_logprob': -0.08328955012596458, 'compression_ratio': 1.7467018469656992, 'no_speech_prob': 0.006125969812273979}, {'id': 20, 'seek': 5770, 'start': 57.7, 'end': 60.400000000000006, 'text': \" what we're looking at today is the next generation of AI tooling.\", 'tokens': [50364, 437, 321, 434, 1237, 412, 965, 307, 264, 958, 5125, 295, 7318, 46593, 13, 50499], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 21, 'seek': 5770, 'start': 60.400000000000006, 'end': 62.0, 'text': \" But as of today, that's all it is.\", 'tokens': [50499, 583, 382, 295, 965, 11, 300, 311, 439, 309, 307, 13, 50579], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 22, 'seek': 5770, 'start': 62.0, 'end': 64.2, 'text': \" It's not capable of replacing any human yet.\", 'tokens': [50579, 467, 311, 406, 8189, 295, 19139, 604, 1952, 1939, 13, 50689], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 23, 'seek': 5770, 'start': 64.2, 'end': 68.4, 'text': ' The big announcement yesterday is that duet AI from Google is now generally available.', 'tokens': [50689, 440, 955, 12847, 5186, 307, 300, 1581, 302, 7318, 490, 3329, 307, 586, 5101, 2435, 13, 50899], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 24, 'seek': 5770, 'start': 68.4, 'end': 72.0, 'text': ' It can be installed into your IDE and provides access to an AI chatbot.', 'tokens': [50899, 467, 393, 312, 8899, 666, 428, 40930, 293, 6417, 2105, 281, 364, 7318, 5081, 18870, 13, 51079], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 25, 'seek': 5770, 'start': 72.0, 'end': 76.7, 'text': ' You can chat in a dedicated panel or get inline suggestions and a telecent just like GitHub Copilot.', 'tokens': [51079, 509, 393, 5081, 294, 257, 8374, 4831, 420, 483, 294, 1889, 13396, 293, 257, 4304, 2207, 445, 411, 23331, 11579, 31516, 13, 51314], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 26, 'seek': 5770, 'start': 76.7, 'end': 78.60000000000001, 'text': \" But unlike Copilot, it's totally free.\", 'tokens': [51314, 583, 8343, 11579, 31516, 11, 309, 311, 3879, 1737, 13, 51409], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 27, 'seek': 5770, 'start': 78.60000000000001, 'end': 81.60000000000001, 'text': ' Well, at least until next year before it becomes $19 per month.', 'tokens': [51409, 1042, 11, 412, 1935, 1826, 958, 1064, 949, 309, 3643, 1848, 3405, 680, 1618, 13, 51559], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 28, 'seek': 5770, 'start': 81.60000000000001, 'end': 84.60000000000001, 'text': \" It's real killer feature, though, is its integration with Google Cloud.\", 'tokens': [51559, 467, 311, 957, 13364, 4111, 11, 1673, 11, 307, 1080, 10980, 365, 3329, 8061, 13, 51709], 'temperature': 0.0, 'avg_logprob': -0.10150922864875538, 'compression_ratio': 1.6246498599439776, 'no_speech_prob': 0.00030184045317582786}, {'id': 29, 'seek': 8460, 'start': 84.6, 'end': 89.0, 'text': ' It allows you to link a Cloud project and then manage all the resources directly from the IDE,', 'tokens': [50364, 467, 4045, 291, 281, 2113, 257, 8061, 1716, 293, 550, 3067, 439, 264, 3593, 3838, 490, 264, 40930, 11, 50584], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 30, 'seek': 8460, 'start': 89.0, 'end': 92.89999999999999, 'text': ' as well as access documentation and generate code samples for your project.', 'tokens': [50584, 382, 731, 382, 2105, 14333, 293, 8460, 3089, 10938, 337, 428, 1716, 13, 50779], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 31, 'seek': 8460, 'start': 92.89999999999999, 'end': 97.1, 'text': \" And it's also worth noting that Google is working on its own Cloud IDE based on VS Code,\", 'tokens': [50779, 400, 309, 311, 611, 3163, 26801, 300, 3329, 307, 1364, 322, 1080, 1065, 8061, 40930, 2361, 322, 25091, 15549, 11, 50989], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 32, 'seek': 8460, 'start': 97.1, 'end': 100.6, 'text': ' called Project IDX, which is not only integrated with this AI,', 'tokens': [50989, 1219, 9849, 7348, 55, 11, 597, 307, 406, 787, 10919, 365, 341, 7318, 11, 51164], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 33, 'seek': 8460, 'start': 100.6, 'end': 105.5, 'text': ' but also has things like iOS and Android emulators built in that run on a Cloud VM.', 'tokens': [51164, 457, 611, 575, 721, 411, 17430, 293, 8853, 846, 39265, 3094, 294, 300, 1190, 322, 257, 8061, 18038, 13, 51409], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 34, 'seek': 8460, 'start': 105.5, 'end': 107.89999999999999, 'text': \" So you don't have to download and configure a bunch of SDKs.\", 'tokens': [51409, 407, 291, 500, 380, 362, 281, 5484, 293, 22162, 257, 3840, 295, 37135, 82, 13, 51529], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 35, 'seek': 8460, 'start': 107.89999999999999, 'end': 111.39999999999999, 'text': ' Now, currently, its underlying AI model is not Gemini Ultra,', 'tokens': [51529, 823, 11, 4362, 11, 1080, 14217, 7318, 2316, 307, 406, 22894, 3812, 20925, 11, 51704], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 36, 'seek': 8460, 'start': 111.39999999999999, 'end': 113.69999999999999, 'text': ' which is claimed to be the best AI programmer out there.', 'tokens': [51704, 597, 307, 12941, 281, 312, 264, 1151, 7318, 32116, 484, 456, 13, 51819], 'temperature': 0.0, 'avg_logprob': -0.12450422181023492, 'compression_ratio': 1.6071428571428572, 'no_speech_prob': 0.04265354201197624}, {'id': 37, 'seek': 11370, 'start': 113.8, 'end': 117.8, 'text': \" If that's true, Duet has the potential to be a GitHub Copilot killer in the future.\", 'tokens': [50369, 759, 300, 311, 2074, 11, 5153, 302, 575, 264, 3995, 281, 312, 257, 23331, 11579, 31516, 13364, 294, 264, 2027, 13, 50569], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 38, 'seek': 11370, 'start': 117.8, 'end': 122.5, 'text': ' But speaking of Copilot killers, JetBrains also just announced their new Copilot killer in December.', 'tokens': [50569, 583, 4124, 295, 11579, 31516, 39369, 11, 28730, 45606, 1292, 611, 445, 7548, 641, 777, 11579, 31516, 13364, 294, 7687, 13, 50804], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 39, 'seek': 11370, 'start': 122.5, 'end': 125.3, 'text': ' It is possible to use Copilot and JetBrains IDEs,', 'tokens': [50804, 467, 307, 1944, 281, 764, 11579, 31516, 293, 28730, 45606, 1292, 7348, 20442, 11, 50944], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 40, 'seek': 11370, 'start': 125.3, 'end': 127.0, 'text': ' but the experience has never been that great.', 'tokens': [50944, 457, 264, 1752, 575, 1128, 668, 300, 869, 13, 51029], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 41, 'seek': 11370, 'start': 127.0, 'end': 130.0, 'text': ' It just feels like it gets in the way, more so than it does in VS Code.', 'tokens': [51029, 467, 445, 3417, 411, 309, 2170, 294, 264, 636, 11, 544, 370, 813, 309, 775, 294, 25091, 15549, 13, 51179], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 42, 'seek': 11370, 'start': 130.0, 'end': 133.0, 'text': ' The AI assistant feels much more natural and well integrated', 'tokens': [51179, 440, 7318, 10994, 3417, 709, 544, 3303, 293, 731, 10919, 51329], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 43, 'seek': 11370, 'start': 133.0, 'end': 137.5, 'text': ' and can do things like chat, refactoring, write documentation, write unit tests,', 'tokens': [51329, 293, 393, 360, 721, 411, 5081, 11, 1895, 578, 3662, 11, 2464, 14333, 11, 2464, 4985, 6921, 11, 51554], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 44, 'seek': 11370, 'start': 137.5, 'end': 140.6, 'text': ' offer companionship, generate commit messages, and so on.', 'tokens': [51554, 2626, 28009, 1210, 11, 8460, 5599, 7897, 11, 293, 370, 322, 13, 51709], 'temperature': 0.0, 'avg_logprob': -0.11204904233905631, 'compression_ratio': 1.719626168224299, 'no_speech_prob': 0.00042993994429707527}, {'id': 45, 'seek': 14060, 'start': 140.7, 'end': 142.7, 'text': ' But with a price tag of $10 per month,', 'tokens': [50369, 583, 365, 257, 3218, 6162, 295, 1848, 3279, 680, 1618, 11, 50469], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 46, 'seek': 14060, 'start': 142.7, 'end': 144.9, 'text': ' it costs nearly as much as the IDE itself.', 'tokens': [50469, 309, 5497, 6217, 382, 709, 382, 264, 40930, 2564, 13, 50579], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 47, 'seek': 14060, 'start': 144.9, 'end': 146.7, 'text': ' And the initial reviews are fairly mixed.', 'tokens': [50579, 400, 264, 5883, 10229, 366, 6457, 7467, 13, 50669], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 48, 'seek': 14060, 'start': 146.7, 'end': 150.5, 'text': \" What's interesting, though, is that it's powered by something called JetBrains AI service.\", 'tokens': [50669, 708, 311, 1880, 11, 1673, 11, 307, 300, 309, 311, 17786, 538, 746, 1219, 28730, 45606, 1292, 7318, 2643, 13, 50859], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 49, 'seek': 14060, 'start': 150.5, 'end': 153.5, 'text': ' And this allows the chatbot to be powered by multiple different models.', 'tokens': [50859, 400, 341, 4045, 264, 5081, 18870, 281, 312, 17786, 538, 3866, 819, 5245, 13, 51009], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 50, 'seek': 14060, 'start': 153.5, 'end': 156.7, 'text': \" There's not a ton of detail around this, but it's an extremely powerful idea.\", 'tokens': [51009, 821, 311, 406, 257, 2952, 295, 2607, 926, 341, 11, 457, 309, 311, 364, 4664, 4005, 1558, 13, 51169], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 51, 'seek': 14060, 'start': 156.7, 'end': 159.5, 'text': ' With Copilot and Duet, you have GPT-4 in Gemini,', 'tokens': [51169, 2022, 11579, 31516, 293, 5153, 302, 11, 291, 362, 26039, 51, 12, 19, 294, 22894, 3812, 11, 51309], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 52, 'seek': 14060, 'start': 159.5, 'end': 163.0, 'text': ' but with JetBrains, you could hypothetically hook up your own fine-tune model,', 'tokens': [51309, 457, 365, 28730, 45606, 1292, 11, 291, 727, 24371, 22652, 6328, 493, 428, 1065, 2489, 12, 83, 2613, 2316, 11, 51484], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 53, 'seek': 14060, 'start': 163.0, 'end': 165.6, 'text': ' like maybe the open-source CodeLama or Mistral,', 'tokens': [51484, 411, 1310, 264, 1269, 12, 41676, 15549, 43, 2404, 420, 20166, 2155, 11, 51614], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 54, 'seek': 14060, 'start': 165.6, 'end': 167.79999999999998, 'text': ' combined with the billions of lines of code at your company,', 'tokens': [51614, 9354, 365, 264, 17375, 295, 3876, 295, 3089, 412, 428, 2237, 11, 51724], 'temperature': 0.0, 'avg_logprob': -0.12438383391409209, 'compression_ratio': 1.606951871657754, 'no_speech_prob': 0.034003451466560364}, {'id': 55, 'seek': 16780, 'start': 167.8, 'end': 171.4, 'text': ' allowing the AI to provide predictable responses based on your coding conventions.', 'tokens': [50364, 8293, 264, 7318, 281, 2893, 27737, 13019, 2361, 322, 428, 17720, 33520, 13, 50544], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 56, 'seek': 16780, 'start': 171.4, 'end': 173.4, 'text': \" That's pretty cool, but at the same time,\", 'tokens': [50544, 663, 311, 1238, 1627, 11, 457, 412, 264, 912, 565, 11, 50644], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 57, 'seek': 16780, 'start': 173.4, 'end': 175.5, 'text': ' GitHub Copilot just leveled up big time.', 'tokens': [50644, 23331, 11579, 31516, 445, 1496, 292, 493, 955, 565, 13, 50749], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 58, 'seek': 16780, 'start': 175.5, 'end': 179.4, 'text': \" Previously, it was based on GPT 3.5, but now it's using GPT-4.\", 'tokens': [50749, 33606, 11, 309, 390, 2361, 322, 26039, 51, 805, 13, 20, 11, 457, 586, 309, 311, 1228, 26039, 51, 12, 19, 13, 50944], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 59, 'seek': 16780, 'start': 179.4, 'end': 181.20000000000002, 'text': ' It now has a dedicated chat window,', 'tokens': [50944, 467, 586, 575, 257, 8374, 5081, 4910, 11, 51034], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 60, 'seek': 16780, 'start': 181.20000000000002, 'end': 183.70000000000002, 'text': ' so you basically have chat GPT in your IDE.', 'tokens': [51034, 370, 291, 1936, 362, 5081, 26039, 51, 294, 428, 40930, 13, 51159], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 61, 'seek': 16780, 'start': 183.70000000000002, 'end': 186.70000000000002, 'text': \" But what's really amazing is that it has this workspace command\", 'tokens': [51159, 583, 437, 311, 534, 2243, 307, 300, 309, 575, 341, 32706, 5622, 51309], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 62, 'seek': 16780, 'start': 186.70000000000002, 'end': 189.5, 'text': ' that allows you to search all the code files in your workspace', 'tokens': [51309, 300, 4045, 291, 281, 3164, 439, 264, 3089, 7098, 294, 428, 32706, 51449], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 63, 'seek': 16780, 'start': 189.5, 'end': 192.0, 'text': ' to write code with the proper context in your project.', 'tokens': [51449, 281, 2464, 3089, 365, 264, 2296, 4319, 294, 428, 1716, 13, 51574], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 64, 'seek': 16780, 'start': 192.0, 'end': 194.70000000000002, 'text': \" So far, I've actually found it most useful for explaining code\", 'tokens': [51574, 407, 1400, 11, 286, 600, 767, 1352, 309, 881, 4420, 337, 13468, 3089, 51709], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 65, 'seek': 16780, 'start': 194.70000000000002, 'end': 196.8, 'text': ' when jumping into an unfamiliar project.', 'tokens': [51709, 562, 11233, 666, 364, 29415, 1716, 13, 51814], 'temperature': 0.0, 'avg_logprob': -0.08327654429844447, 'compression_ratio': 1.6779661016949152, 'no_speech_prob': 0.0023878291249275208}, {'id': 66, 'seek': 19680, 'start': 196.9, 'end': 200.9, 'text': \" In other words, it makes it way easier to figure out what the hell is going on with this guy's spaghetti code.\", 'tokens': [50369, 682, 661, 2283, 11, 309, 1669, 309, 636, 3571, 281, 2573, 484, 437, 264, 4921, 307, 516, 322, 365, 341, 2146, 311, 28556, 3089, 13, 50569], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 67, 'seek': 19680, 'start': 200.9, 'end': 202.70000000000002, 'text': ' It also now writes your commit messages,', 'tokens': [50569, 467, 611, 586, 13657, 428, 5599, 7897, 11, 50659], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 68, 'seek': 19680, 'start': 202.70000000000002, 'end': 206.4, 'text': ' and is also available in the terminal to explain and refactor commands.', 'tokens': [50659, 293, 307, 611, 2435, 294, 264, 14709, 281, 2903, 293, 1895, 15104, 16901, 13, 50844], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 69, 'seek': 19680, 'start': 206.4, 'end': 208.60000000000002, 'text': \" But there's one big problem with these AI tools.\", 'tokens': [50844, 583, 456, 311, 472, 955, 1154, 365, 613, 7318, 3873, 13, 50954], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 70, 'seek': 19680, 'start': 208.60000000000002, 'end': 212.60000000000002, 'text': \" Sometimes they spit out suggestions from code and repos that you're not allowed to use.\", 'tokens': [50954, 4803, 436, 22127, 484, 13396, 490, 3089, 293, 1085, 329, 300, 291, 434, 406, 4350, 281, 764, 13, 51154], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 71, 'seek': 19680, 'start': 212.60000000000002, 'end': 214.10000000000002, 'text': \" And I really can't go back to jail,\", 'tokens': [51154, 400, 286, 534, 393, 380, 352, 646, 281, 10511, 11, 51229], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 72, 'seek': 19680, 'start': 214.10000000000002, 'end': 217.4, 'text': ' but luckily, Copilot will now search across billions of files in GitHub', 'tokens': [51229, 457, 22880, 11, 11579, 31516, 486, 586, 3164, 2108, 17375, 295, 7098, 294, 23331, 51394], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 73, 'seek': 19680, 'start': 217.4, 'end': 219.8, 'text': ' and will return the licenses on any similar code.', 'tokens': [51394, 293, 486, 2736, 264, 32821, 322, 604, 2531, 3089, 13, 51514], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 74, 'seek': 19680, 'start': 219.8, 'end': 222.9, 'text': \" And that means you can be relatively confident that you're not stealing someone's code.\", 'tokens': [51514, 400, 300, 1355, 291, 393, 312, 7226, 6679, 300, 291, 434, 406, 19757, 1580, 311, 3089, 13, 51669], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 75, 'seek': 19680, 'start': 222.9, 'end': 225.10000000000002, 'text': \" Well, I mean, you are stealing it, but you're allowed to.\", 'tokens': [51669, 1042, 11, 286, 914, 11, 291, 366, 19757, 309, 11, 457, 291, 434, 4350, 281, 13, 51779], 'temperature': 0.0, 'avg_logprob': -0.0804601900505297, 'compression_ratio': 1.7336814621409922, 'no_speech_prob': 0.0011062705889344215}, {'id': 76, 'seek': 22510, 'start': 225.2, 'end': 228.0, 'text': ' Overall, these changes are pretty amazing and extremely useful.', 'tokens': [50369, 18420, 11, 613, 2962, 366, 1238, 2243, 293, 4664, 4420, 13, 50509], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 77, 'seek': 22510, 'start': 228.0, 'end': 230.79999999999998, 'text': \" These tools still can't build complex projects out of nowhere,\", 'tokens': [50509, 1981, 3873, 920, 393, 380, 1322, 3997, 4455, 484, 295, 11159, 11, 50649], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 78, 'seek': 22510, 'start': 230.79999999999998, 'end': 233.0, 'text': ' but the big question is where are we going from here?', 'tokens': [50649, 457, 264, 955, 1168, 307, 689, 366, 321, 516, 490, 510, 30, 50759], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 79, 'seek': 22510, 'start': 233.0, 'end': 235.79999999999998, 'text': \" Currently, Copilot doesn't run your code or create new files,\", 'tokens': [50759, 19964, 11, 11579, 31516, 1177, 380, 1190, 428, 3089, 420, 1884, 777, 7098, 11, 50899], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 80, 'seek': 22510, 'start': 235.79999999999998, 'end': 237.2, 'text': \" but I think we're going there eventually,\", 'tokens': [50899, 457, 286, 519, 321, 434, 516, 456, 4728, 11, 50969], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 81, 'seek': 22510, 'start': 237.2, 'end': 239.79999999999998, 'text': \" like you might be able to just take your client's requirements and say,\", 'tokens': [50969, 411, 291, 1062, 312, 1075, 281, 445, 747, 428, 6423, 311, 7728, 293, 584, 11, 51099], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 82, 'seek': 22510, 'start': 239.79999999999998, 'end': 241.2, 'text': ' hey, build this thing in Django,', 'tokens': [51099, 4177, 11, 1322, 341, 551, 294, 33464, 17150, 11, 51169], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 83, 'seek': 22510, 'start': 241.2, 'end': 243.6, 'text': ' then Copilot will run the commands, create the files,', 'tokens': [51169, 550, 11579, 31516, 486, 1190, 264, 16901, 11, 1884, 264, 7098, 11, 51289], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 84, 'seek': 22510, 'start': 243.6, 'end': 246.4, 'text': ' and run the unit tests required to make that a reality.', 'tokens': [51289, 293, 1190, 264, 4985, 6921, 4739, 281, 652, 300, 257, 4103, 13, 51429], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 85, 'seek': 22510, 'start': 246.4, 'end': 249.4, 'text': \" Then you'll continue fine tuning it with multiple shots or prompts\", 'tokens': [51429, 1396, 291, 603, 2354, 2489, 15164, 309, 365, 3866, 8305, 420, 41095, 51579], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 86, 'seek': 22510, 'start': 249.4, 'end': 252.79999999999998, 'text': \" until it builds exactly what you're looking for without ever touching a line of code.\", 'tokens': [51579, 1826, 309, 15182, 2293, 437, 291, 434, 1237, 337, 1553, 1562, 11175, 257, 1622, 295, 3089, 13, 51749], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 87, 'seek': 22510, 'start': 252.79999999999998, 'end': 254.79999999999998, 'text': ' Another missing piece is image data.', 'tokens': [51749, 3996, 5361, 2522, 307, 3256, 1412, 13, 51849], 'temperature': 0.0, 'avg_logprob': -0.08541493188767206, 'compression_ratio': 1.7268170426065164, 'no_speech_prob': 0.0013309800997376442}, {'id': 88, 'seek': 25480, 'start': 254.8, 'end': 257.6, 'text': ' There are already tools that can convert a screenshot into code,', 'tokens': [50364, 821, 366, 1217, 3873, 300, 393, 7620, 257, 27712, 666, 3089, 11, 50504], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 89, 'seek': 25480, 'start': 257.6, 'end': 258.90000000000003, 'text': ' and as these tools get better,', 'tokens': [50504, 293, 382, 613, 3873, 483, 1101, 11, 50569], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 90, 'seek': 25480, 'start': 258.90000000000003, 'end': 261.3, 'text': \" we'll likely see them integrated directly in the IDE.\", 'tokens': [50569, 321, 603, 3700, 536, 552, 10919, 3838, 294, 264, 40930, 13, 50689], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 91, 'seek': 25480, 'start': 261.3, 'end': 263.1, 'text': ' Now, even if this stuff does get really good,', 'tokens': [50689, 823, 11, 754, 498, 341, 1507, 775, 483, 534, 665, 11, 50779], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 92, 'seek': 25480, 'start': 263.1, 'end': 264.8, 'text': \" I wouldn't be discouraged as a programmer.\", 'tokens': [50779, 286, 2759, 380, 312, 35010, 382, 257, 32116, 13, 50864], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 93, 'seek': 25480, 'start': 264.8, 'end': 266.7, 'text': ' Right now is one hell of a time to be alive.', 'tokens': [50864, 1779, 586, 307, 472, 4921, 295, 257, 565, 281, 312, 5465, 13, 50959], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 94, 'seek': 25480, 'start': 266.7, 'end': 268.1, 'text': ' Code is just a means to an end.', 'tokens': [50959, 15549, 307, 445, 257, 1355, 281, 364, 917, 13, 51029], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 95, 'seek': 25480, 'start': 268.1, 'end': 269.90000000000003, 'text': ' Even if programming becomes obsolete,', 'tokens': [51029, 2754, 498, 9410, 3643, 46333, 11, 51119], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 96, 'seek': 25480, 'start': 269.90000000000003, 'end': 272.8, 'text': \" there'll still be engineers pushing the limits of whatever comes next.\", 'tokens': [51119, 456, 603, 920, 312, 11955, 7380, 264, 10406, 295, 2035, 1487, 958, 13, 51264], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 97, 'seek': 25480, 'start': 272.8, 'end': 274.7, 'text': ' Like we still need to develop robots,', 'tokens': [51264, 1743, 321, 920, 643, 281, 1499, 14733, 11, 51359], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 98, 'seek': 25480, 'start': 274.7, 'end': 276.40000000000003, 'text': ' brain ships, quantum computers,', 'tokens': [51359, 3567, 11434, 11, 13018, 10807, 11, 51444], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 99, 'seek': 25480, 'start': 276.40000000000003, 'end': 277.40000000000003, 'text': ' euthanasia pods,', 'tokens': [51444, 308, 2910, 14292, 654, 31925, 11, 51494], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 100, 'seek': 25480, 'start': 277.40000000000003, 'end': 278.8, 'text': ' laser guns, space travel,', 'tokens': [51494, 12530, 10153, 11, 1901, 3147, 11, 51564], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 101, 'seek': 25480, 'start': 278.8, 'end': 279.6, 'text': ' time travel,', 'tokens': [51564, 565, 3147, 11, 51604], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 102, 'seek': 25480, 'start': 279.6, 'end': 281.5, 'text': ' and all sorts of other sci-fi bullshit.', 'tokens': [51604, 293, 439, 7527, 295, 661, 2180, 12, 13325, 22676, 13, 51699], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 103, 'seek': 25480, 'start': 281.5, 'end': 284.5, 'text': \" And it's going to take some good old-fashioned problem-solving engineers\", 'tokens': [51699, 400, 309, 311, 516, 281, 747, 512, 665, 1331, 12, 37998, 1154, 12, 30926, 798, 11955, 51849], 'temperature': 0.0, 'avg_logprob': -0.1064453125, 'compression_ratio': 1.6742424242424243, 'no_speech_prob': 0.0005083418800495565}, {'id': 104, 'seek': 28450, 'start': 284.5, 'end': 286.1, 'text': ' to do that. So stay optimistic.', 'tokens': [50364, 281, 360, 300, 13, 407, 1754, 19397, 13, 50444], 'temperature': 0.0, 'avg_logprob': -0.2322467753761693, 'compression_ratio': 1.1666666666666667, 'no_speech_prob': 0.02355037070810795}, {'id': 105, 'seek': 28450, 'start': 286.1, 'end': 287.2, 'text': ' This has been the Code Report.', 'tokens': [50444, 639, 575, 668, 264, 15549, 16057, 13, 50499], 'temperature': 0.0, 'avg_logprob': -0.2322467753761693, 'compression_ratio': 1.1666666666666667, 'no_speech_prob': 0.02355037070810795}, {'id': 106, 'seek': 28450, 'start': 287.2, 'end': 288.2, 'text': ' Thanks for watching,', 'tokens': [50499, 2561, 337, 1976, 11, 50549], 'temperature': 0.0, 'avg_logprob': -0.2322467753761693, 'compression_ratio': 1.1666666666666667, 'no_speech_prob': 0.02355037070810795}, {'id': 107, 'seek': 28450, 'start': 288.2, 'end': 289.7, 'text': ' and I will see you in the next one.', 'tokens': [50549, 293, 286, 486, 536, 291, 294, 264, 958, 472, 13, 50624], 'temperature': 0.0, 'avg_logprob': -0.2322467753761693, 'compression_ratio': 1.1666666666666667, 'no_speech_prob': 0.02355037070810795}]\n"
          ]
        }
      ],
      "source": [
        "print(result[\"segments\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
